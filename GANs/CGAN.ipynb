{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# derived from https://machinelearningmastery.com/how-to-implement-pix2pix-gan-models-from-scratch-with-keras/\n",
    "\n",
    "# https://machinelearningmastery.com/how-to-develop-a-pix2pix-gan-for-image-to-image-translation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/usr/lib/python3/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/lib/python3/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/lib/python3/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/lib/python3/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/lib/python3/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/lib/python3/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/lib/python3/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/lib/python3/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/lib/python3/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/lib/python3/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/lib/python3/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/lib/python3/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (60000, 28, 28) (60000,)\n",
      "Test (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets.fashion_mnist import load_data\n",
    "# load the images into memory\n",
    "(trainX, trainy), (testX, testy) = load_data()\n",
    "# summarize the shape of the dataset\n",
    "print('Train', trainX.shape, trainy.shape)\n",
    "print('Test', testX.shape, testy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "def receptive_field(output_size, kernel_size, stride_size):\n",
    "    return (output_size - 1) * stride_size + kernel_size\n",
    "\n",
    "# example of defining a 70x70 patchgan discriminator model\n",
    "from keras.optimizers import Adam\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.models import Model\n",
    "from keras.models import Input\n",
    "from keras.layers import Conv2D, Conv2DTranspose, Dropout\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Concatenate\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import numpy as np\n",
    "\n",
    "# define the discriminator model\n",
    "def define_discriminator(image_shape):\n",
    "    # weight initialization\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    # source image input\n",
    "    in_src_image = Input(shape=image_shape)\n",
    "    # target image input\n",
    "    in_target_image = Input(shape=image_shape)\n",
    "    # concatenate images channel-wise\n",
    "    merged = Concatenate()([in_src_image, in_target_image])\n",
    "    # C64\n",
    "    d = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(merged)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    # C128\n",
    "    d = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    # C256\n",
    "    d = Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    # C512\n",
    "    d = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    # second last output layer\n",
    "    d = Conv2D(512, (4,4), padding='same', kernel_initializer=init)(d)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    # patch output\n",
    "    d = Conv2D(1, (4,4), padding='same', kernel_initializer=init)(d)\n",
    "    patch_out = Activation('sigmoid')(d)\n",
    "    # define model\n",
    "    model = Model([in_src_image, in_target_image], patch_out)\n",
    "    # compile model\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, loss_weights=[0.5])\n",
    "    return model\n",
    "\n",
    "# define an encoder block\n",
    "def define_encoder_block(layer_in, n_filters, batchnorm=True):\n",
    "# weight initialization\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    # add downsampling layer\n",
    "    g = Conv2D(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n",
    "    # conditionally add batch normalization\n",
    "    if batchnorm:\n",
    "        g = BatchNormalization()(g, training=True)\n",
    "    # leaky relu activation\n",
    "    g = LeakyReLU(alpha=0.2)(g)\n",
    "    return g\n",
    " \n",
    "# define a decoder block\n",
    "def decoder_block(layer_in, skip_in, n_filters, dropout=True):\n",
    "    # weight initialization\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    # add upsampling layer\n",
    "    g = Conv2DTranspose(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n",
    "    # add batch normalization\n",
    "    g = BatchNormalization()(g, training=True)\n",
    "    # conditionally add dropout\n",
    "    if dropout:\n",
    "        g = Dropout(0.5)(g, training=True)\n",
    "    # merge with skip connection\n",
    "    g = Concatenate()([g, skip_in])\n",
    "    # relu activation\n",
    "    g = Activation('relu')(g)\n",
    "    return g\n",
    " \n",
    "# define the standalone generator model\n",
    "def define_generator(image_shape=(256,256,3)):\n",
    "    # weight initialization\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    # image input\n",
    "    in_image = Input(shape=image_shape)\n",
    "    # encoder model: C64-C128-C256-C512-C512-C512-C512-C512\n",
    "    e1 = define_encoder_block(in_image, 64, batchnorm=False)\n",
    "    e2 = define_encoder_block(e1, 128)\n",
    "    e3 = define_encoder_block(e2, 256)\n",
    "    e4 = define_encoder_block(e3, 512)\n",
    "    e5 = define_encoder_block(e4, 512)\n",
    "    e6 = define_encoder_block(e5, 512)\n",
    "    e7 = define_encoder_block(e6, 512)\n",
    "    # bottleneck, no batch norm and relu\n",
    "    b = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(e7)\n",
    "    b = Activation('relu')(b)\n",
    "    # decoder model: CD512-CD1024-CD1024-C1024-C1024-C512-C256-C128\n",
    "    d1 = decoder_block(b, e7, 512)\n",
    "    d2 = decoder_block(d1, e6, 512)\n",
    "    d3 = decoder_block(d2, e5, 512)\n",
    "    d4 = decoder_block(d3, e4, 512, dropout=False)\n",
    "    d5 = decoder_block(d4, e3, 256, dropout=False)\n",
    "    d6 = decoder_block(d5, e2, 128, dropout=False)\n",
    "    d7 = decoder_block(d6, e1, 64, dropout=False)\n",
    "    # output\n",
    "    g = Conv2DTranspose(3, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d7)\n",
    "    out_image = Activation('tanh')(g)\n",
    "    # define model\n",
    "    model = Model(in_image, out_image)\n",
    "    return model\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_17 (InputLayer)           (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_8 (Model)                 (None, 256, 256, 3)  54429315    input_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "model_7 (Model)                 (None, 16, 16, 1)    6968257     input_17[0][0]                   \n",
      "                                                                 model_8[1][0]                    \n",
      "==================================================================================================\n",
      "Total params: 61,397,572\n",
      "Trainable params: 54,419,459\n",
      "Non-trainable params: 6,978,113\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def define_gan(g_model, d_model, image_shape):\n",
    "    # make weights in the discriminator not trainable\n",
    "    d_model.trainable = False\n",
    "    # define the source image\n",
    "    in_src = Input(shape=image_shape)\n",
    "    # connect the source image to the generator input\n",
    "    gen_out = g_model(in_src)\n",
    "    # connect the source input and generator output to the discriminator input\n",
    "    dis_out = d_model([in_src, gen_out])\n",
    "    # src image as input, generated image and classification output\n",
    "    model = Model(in_src, [dis_out, gen_out])\n",
    "    # compile model\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    model.compile(loss=['binary_crossentropy', 'mae'], optimizer=opt, loss_weights=[1,100])\n",
    "    return model\n",
    "\n",
    "# define image shape\n",
    "image_shape = (256,256,3)\n",
    "# define the models\n",
    "d_model = define_discriminator(image_shape)\n",
    "g_model = define_generator(image_shape)\n",
    "# define the composite model\n",
    "gan_model = define_gan(g_model, d_model, image_shape)\n",
    "# summarize the model\n",
    "gan_model.summary()\n",
    "# plot the model\n",
    "plot_model(gan_model, to_file='gan_model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_real_samples(dataset, n_samples, patch_shape):\n",
    "    # unpack dataset\n",
    "    trainA, trainB = dataset\n",
    "    # choose random instances\n",
    "    ix = np.random.randint(0, trainA.shape[0], n_samples)\n",
    "    # retrieve selected images\n",
    "    X1, X2 = trainA[ix], trainB[ix]\n",
    "    # generate 'real' class labels (1)\n",
    "    y = np.ones((n_samples, patch_shape, patch_shape, 1))\n",
    "    return [X1, X2], y\n",
    "\n",
    "# generate a batch of images, returns images and targets\n",
    "def generate_fake_samples(g_model, samples, patch_shape):\n",
    "    # generate fake instance\n",
    "    X = g_model.predict(samples)\n",
    "    # create 'fake' class labels (0)\n",
    "    y = np.zeros((len(X), patch_shape, patch_shape, 1))\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(d_model, g_model, gan_model, dataset, n_epochs=100, n_batch=1, n_patch=16):\n",
    "    # unpack dataset\n",
    "    trainA, trainB = dataset\n",
    "    # calculate the number of batches per training epoch\n",
    "    bat_per_epo = int(len(trainA) / n_batch)\n",
    "    # calculate the number of training iterations\n",
    "    n_steps = bat_per_epo * n_epochs\n",
    "    # manually enumerate epochs\n",
    "    for i in range(n_steps):\n",
    "        # select a batch of real samples\n",
    "        [X_realA, X_realB], y_real = generate_real_samples(dataset, n_batch, n_patch)\n",
    "        # generate a batch of fake samples\n",
    "        X_fakeB, y_fake = generate_fake_samples(g_model, X_realA, n_patch)\n",
    "        # update discriminator for real samples\n",
    "        d_loss1 = d_model.train_on_batch([X_realA, X_realB], y_real)\n",
    "        # update discriminator for generated samples\n",
    "        d_loss2 = d_model.train_on_batch([X_realA, X_fakeB], y_fake)\n",
    "        # update the generator\n",
    "        g_loss, _, _ = gan_model.train_on_batch(X_realA, [y_real, X_realB])\n",
    "        # summarize performance\n",
    "        print('>%d, d1[%.3f] d2[%.3f] g[%.3f]' % (i+1, d_loss1, d_loss2, g_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1, d1[0.344] d2[0.753] g[55.212]\n",
      ">2, d1[0.269] d2[0.623] g[53.178]\n",
      ">3, d1[0.338] d2[0.520] g[51.122]\n",
      ">4, d1[0.393] d2[0.472] g[49.105]\n",
      ">5, d1[0.399] d2[0.434] g[47.081]\n",
      ">6, d1[0.395] d2[0.421] g[45.112]\n",
      ">7, d1[0.409] d2[0.392] g[42.980]\n",
      ">8, d1[0.378] d2[0.409] g[41.180]\n",
      ">9, d1[0.379] d2[0.393] g[39.347]\n",
      ">10, d1[0.354] d2[0.378] g[37.829]\n",
      ">11, d1[0.333] d2[0.357] g[36.456]\n",
      ">12, d1[0.315] d2[0.317] g[35.115]\n",
      ">13, d1[0.319] d2[0.308] g[34.183]\n",
      ">14, d1[0.282] d2[0.278] g[33.212]\n",
      ">15, d1[0.270] d2[0.251] g[32.444]\n",
      ">16, d1[0.249] d2[0.289] g[31.940]\n",
      ">17, d1[0.258] d2[0.222] g[31.314]\n",
      ">18, d1[0.256] d2[0.220] g[30.894]\n",
      ">19, d1[0.220] d2[0.177] g[30.496]\n",
      ">20, d1[0.184] d2[0.275] g[30.739]\n",
      ">21, d1[0.629] d2[0.436] g[29.910]\n",
      ">22, d1[0.406] d2[0.195] g[28.752]\n",
      ">23, d1[0.227] d2[0.538] g[29.672]\n",
      ">24, d1[1.009] d2[0.075] g[27.994]\n",
      ">25, d1[0.446] d2[0.348] g[27.740]\n",
      ">26, d1[0.217] d2[0.527] g[28.282]\n",
      ">27, d1[0.697] d2[0.193] g[27.458]\n",
      ">28, d1[0.579] d2[0.757] g[27.447]\n",
      ">29, d1[0.656] d2[0.263] g[27.097]\n",
      ">30, d1[0.615] d2[0.348] g[26.912]\n",
      ">31, d1[0.484] d2[0.334] g[26.864]\n",
      ">32, d1[0.406] d2[0.321] g[26.908]\n",
      ">33, d1[0.372] d2[0.326] g[26.801]\n",
      ">34, d1[0.350] d2[0.369] g[26.847]\n",
      ">35, d1[0.446] d2[0.432] g[26.784]\n",
      ">36, d1[0.494] d2[0.505] g[26.784]\n",
      ">37, d1[0.569] d2[0.394] g[26.660]\n",
      ">38, d1[0.553] d2[0.370] g[26.668]\n",
      ">39, d1[0.494] d2[0.361] g[26.635]\n",
      ">40, d1[0.451] d2[0.328] g[26.632]\n",
      ">41, d1[0.413] d2[0.332] g[26.700]\n",
      ">42, d1[0.393] d2[0.330] g[26.670]\n",
      ">43, d1[0.349] d2[0.317] g[26.760]\n",
      ">44, d1[0.378] d2[0.352] g[26.771]\n",
      ">45, d1[0.379] d2[0.341] g[26.851]\n",
      ">46, d1[0.436] d2[0.411] g[26.837]\n",
      ">47, d1[0.446] d2[0.379] g[26.857]\n",
      ">48, d1[0.488] d2[0.330] g[26.843]\n",
      ">49, d1[0.379] d2[0.300] g[26.909]\n",
      ">50, d1[0.361] d2[0.271] g[26.865]\n",
      ">51, d1[0.306] d2[0.279] g[26.955]\n",
      ">52, d1[0.310] d2[0.276] g[26.971]\n",
      ">53, d1[0.274] d2[0.345] g[27.229]\n",
      ">54, d1[0.414] d2[0.342] g[27.189]\n",
      ">55, d1[0.445] d2[0.362] g[27.136]\n",
      ">56, d1[0.468] d2[0.295] g[27.064]\n",
      ">57, d1[0.387] d2[0.289] g[27.106]\n",
      ">58, d1[0.326] d2[0.269] g[27.066]\n",
      ">59, d1[0.293] d2[0.224] g[27.125]\n",
      ">60, d1[0.256] d2[0.231] g[27.164]\n",
      ">61, d1[0.223] d2[0.257] g[27.420]\n",
      ">62, d1[0.282] d2[0.277] g[27.387]\n",
      ">63, d1[0.333] d2[0.357] g[27.794]\n",
      ">64, d1[0.426] d2[0.247] g[27.628]\n",
      ">65, d1[0.330] d2[0.228] g[27.599]\n",
      ">66, d1[0.206] d2[0.156] g[27.538]\n",
      ">67, d1[0.137] d2[0.161] g[27.638]\n",
      ">68, d1[0.134] d2[0.167] g[27.797]\n",
      ">69, d1[0.188] d2[0.245] g[28.122]\n",
      ">70, d1[0.340] d2[0.281] g[28.098]\n",
      ">71, d1[0.400] d2[0.321] g[28.241]\n",
      ">72, d1[0.292] d2[0.076] g[27.500]\n",
      ">73, d1[0.124] d2[0.237] g[28.128]\n",
      ">74, d1[0.192] d2[0.079] g[27.764]\n",
      ">75, d1[0.093] d2[0.098] g[27.809]\n",
      ">76, d1[0.041] d2[0.079] g[28.060]\n",
      ">77, d1[0.104] d2[0.118] g[28.075]\n",
      ">78, d1[0.130] d2[0.155] g[28.443]\n",
      ">79, d1[0.162] d2[0.115] g[28.306]\n",
      ">80, d1[0.146] d2[0.141] g[28.434]\n",
      ">81, d1[0.134] d2[0.089] g[28.304]\n",
      ">82, d1[0.063] d2[0.075] g[28.457]\n",
      ">83, d1[0.059] d2[0.077] g[28.569]\n",
      ">84, d1[0.079] d2[0.090] g[28.665]\n",
      ">85, d1[0.117] d2[0.120] g[28.910]\n",
      ">86, d1[0.126] d2[0.087] g[28.574]\n",
      ">87, d1[0.074] d2[0.057] g[28.552]\n",
      ">88, d1[0.041] d2[0.052] g[28.736]\n",
      ">89, d1[0.043] d2[0.039] g[28.767]\n",
      ">90, d1[0.047] d2[0.055] g[28.913]\n",
      ">91, d1[0.046] d2[0.048] g[28.891]\n",
      ">92, d1[0.053] d2[0.056] g[29.026]\n",
      ">93, d1[0.054] d2[0.056] g[29.101]\n",
      ">94, d1[0.026] d2[0.023] g[29.304]\n",
      ">95, d1[0.055] d2[0.088] g[29.700]\n",
      ">96, d1[0.099] d2[0.048] g[28.976]\n",
      ">97, d1[0.022] d2[0.063] g[29.617]\n",
      ">98, d1[0.052] d2[0.033] g[29.252]\n",
      ">99, d1[0.031] d2[0.072] g[29.745]\n",
      ">100, d1[0.091] d2[0.094] g[29.816]\n",
      ">101, d1[0.056] d2[0.026] g[29.418]\n",
      ">102, d1[0.031] d2[0.056] g[29.719]\n",
      ">103, d1[0.034] d2[0.040] g[29.649]\n",
      ">104, d1[0.066] d2[0.340] g[30.974]\n",
      ">105, d1[1.521] d2[0.116] g[28.707]\n",
      ">106, d1[0.021] d2[0.207] g[29.298]\n",
      ">107, d1[0.033] d2[0.054] g[29.198]\n",
      ">108, d1[0.087] d2[0.122] g[29.193]\n",
      ">109, d1[0.120] d2[0.140] g[29.381]\n",
      ">110, d1[0.086] d2[0.042] g[28.902]\n",
      ">111, d1[0.025] d2[0.155] g[30.235]\n",
      ">112, d1[0.621] d2[1.052] g[30.701]\n",
      ">113, d1[1.580] d2[0.011] g[29.484]\n",
      ">114, d1[1.019] d2[0.080] g[27.095]\n",
      ">115, d1[0.064] d2[0.265] g[27.064]\n",
      ">116, d1[0.027] d2[0.168] g[27.532]\n",
      ">117, d1[0.063] d2[0.100] g[27.647]\n",
      ">118, d1[0.040] d2[0.070] g[27.888]\n",
      ">119, d1[0.099] d2[0.430] g[28.717]\n",
      ">120, d1[0.482] d2[0.125] g[27.700]\n",
      ">121, d1[0.064] d2[0.253] g[28.927]\n",
      ">122, d1[0.164] d2[0.055] g[28.345]\n",
      ">123, d1[0.046] d2[0.114] g[28.592]\n",
      ">124, d1[0.046] d2[0.080] g[28.801]\n",
      ">125, d1[0.024] d2[0.104] g[29.235]\n",
      ">126, d1[0.234] d2[0.235] g[29.621]\n",
      ">127, d1[0.112] d2[0.023] g[29.119]\n",
      ">128, d1[0.028] d2[0.037] g[28.812]\n",
      ">129, d1[0.016] d2[0.063] g[28.764]\n",
      ">130, d1[0.027] d2[0.059] g[29.015]\n",
      ">131, d1[0.045] d2[0.113] g[29.519]\n",
      ">132, d1[0.105] d2[0.097] g[29.535]\n",
      ">133, d1[0.051] d2[0.056] g[29.474]\n",
      ">134, d1[0.027] d2[0.049] g[29.835]\n",
      ">135, d1[0.056] d2[0.089] g[30.111]\n",
      ">136, d1[0.061] d2[0.070] g[30.198]\n",
      ">137, d1[0.081] d2[0.101] g[30.330]\n",
      ">138, d1[0.051] d2[0.025] g[29.917]\n",
      ">139, d1[0.017] d2[0.300] g[30.922]\n",
      ">140, d1[0.269] d2[0.217] g[30.257]\n",
      ">141, d1[0.018] d2[0.029] g[30.362]\n",
      ">142, d1[0.047] d2[0.054] g[29.782]\n",
      ">143, d1[0.012] d2[0.061] g[29.906]\n",
      ">144, d1[0.085] d2[0.187] g[31.235]\n",
      ">145, d1[0.543] d2[0.539] g[30.977]\n",
      ">146, d1[0.081] d2[0.021] g[30.715]\n",
      ">147, d1[0.176] d2[0.391] g[30.206]\n",
      ">148, d1[0.018] d2[0.082] g[30.700]\n",
      ">149, d1[0.112] d2[0.049] g[29.618]\n",
      ">150, d1[0.014] d2[0.156] g[30.985]\n",
      ">151, d1[0.219] d2[0.129] g[29.836]\n",
      ">152, d1[0.016] d2[0.318] g[31.913]\n",
      ">153, d1[1.248] d2[0.106] g[28.223]\n",
      ">154, d1[0.005] d2[0.745] g[31.320]\n",
      ">155, d1[1.060] d2[0.042] g[29.470]\n",
      ">156, d1[0.035] d2[0.073] g[28.895]\n",
      ">157, d1[0.009] d2[0.112] g[29.461]\n",
      ">158, d1[0.050] d2[0.058] g[29.498]\n",
      ">159, d1[0.046] d2[0.108] g[30.037]\n",
      ">160, d1[0.133] d2[0.151] g[30.710]\n",
      ">161, d1[0.107] d2[0.019] g[30.062]\n",
      ">162, d1[0.014] d2[0.045] g[29.769]\n",
      ">163, d1[0.008] d2[0.092] g[30.724]\n",
      ">164, d1[0.100] d2[0.051] g[30.017]\n",
      ">165, d1[0.023] d2[0.202] g[32.129]\n",
      ">166, d1[0.996] d2[0.077] g[28.279]\n",
      ">167, d1[0.001] d2[1.654] g[31.928]\n",
      ">168, d1[1.462] d2[0.005] g[30.814]\n",
      ">169, d1[0.888] d2[0.040] g[27.895]\n",
      ">170, d1[0.005] d2[0.344] g[28.171]\n",
      ">171, d1[0.008] d2[0.085] g[28.636]\n",
      ">172, d1[0.037] d2[0.067] g[28.652]\n",
      ">173, d1[0.049] d2[0.298] g[29.389]\n",
      ">174, d1[0.200] d2[0.260] g[29.720]\n",
      ">175, d1[0.264] d2[0.250] g[29.498]\n",
      ">176, d1[0.080] d2[0.114] g[29.798]\n",
      ">177, d1[0.071] d2[0.059] g[29.518]\n",
      ">178, d1[0.044] d2[0.121] g[29.901]\n",
      ">179, d1[0.113] d2[0.163] g[30.547]\n",
      ">180, d1[0.212] d2[0.104] g[29.785]\n",
      ">181, d1[0.021] d2[0.123] g[30.972]\n",
      ">182, d1[0.218] d2[0.197] g[31.134]\n",
      ">183, d1[0.118] d2[0.015] g[30.461]\n",
      ">184, d1[0.013] d2[0.071] g[30.372]\n",
      ">185, d1[0.029] d2[0.075] g[30.967]\n",
      ">186, d1[0.135] d2[0.283] g[32.182]\n",
      ">187, d1[1.096] d2[0.018] g[29.076]\n",
      ">188, d1[0.001] d2[0.789] g[31.663]\n",
      ">189, d1[0.450] d2[0.007] g[30.872]\n",
      ">190, d1[0.044] d2[0.012] g[30.212]\n",
      ">191, d1[0.006] d2[0.018] g[29.757]\n",
      ">192, d1[0.005] d2[0.056] g[29.342]\n",
      ">193, d1[0.007] d2[0.384] g[30.562]\n",
      ">194, d1[0.303] d2[0.124] g[29.761]\n",
      ">195, d1[0.061] d2[0.108] g[29.713]\n",
      ">196, d1[0.045] d2[0.107] g[30.249]\n",
      ">197, d1[0.064] d2[0.094] g[30.509]\n",
      ">198, d1[0.177] d2[0.605] g[32.461]\n",
      ">199, d1[1.501] d2[0.009] g[30.960]\n",
      ">200, d1[0.072] d2[0.025] g[29.662]\n",
      ">201, d1[0.004] d2[0.060] g[29.301]\n",
      ">202, d1[0.003] d2[0.095] g[29.529]\n",
      ">203, d1[0.011] d2[0.075] g[29.785]\n",
      ">204, d1[0.044] d2[0.113] g[30.282]\n",
      ">205, d1[0.116] d2[0.144] g[30.408]\n",
      ">206, d1[0.135] d2[0.161] g[30.868]\n",
      ">207, d1[0.092] d2[0.055] g[30.463]\n",
      ">208, d1[0.034] d2[0.121] g[31.546]\n",
      ">209, d1[0.201] d2[0.158] g[31.430]\n",
      ">210, d1[0.028] d2[0.015] g[31.351]\n",
      ">211, d1[0.060] d2[0.056] g[30.456]\n",
      ">212, d1[0.013] d2[0.337] g[32.955]\n",
      ">213, d1[1.969] d2[0.007] g[31.486]\n",
      ">214, d1[0.752] d2[0.157] g[28.244]\n",
      ">215, d1[0.001] d2[0.575] g[30.793]\n",
      ">216, d1[0.245] d2[0.015] g[30.446]\n",
      ">217, d1[0.074] d2[0.021] g[29.718]\n",
      ">218, d1[0.007] d2[0.041] g[29.379]\n",
      ">219, d1[0.004] d2[0.068] g[29.502]\n",
      ">220, d1[0.011] d2[0.078] g[29.965]\n",
      ">221, d1[0.064] d2[0.155] g[30.781]\n",
      ">222, d1[0.211] d2[0.263] g[31.404]\n",
      ">223, d1[0.376] d2[0.086] g[29.121]\n",
      ">224, d1[0.002] d2[0.481] g[32.175]\n",
      ">225, d1[0.886] d2[0.011] g[30.504]\n",
      ">226, d1[0.012] d2[0.028] g[29.936]\n",
      ">227, d1[0.002] d2[0.053] g[29.797]\n",
      ">228, d1[0.003] d2[0.085] g[29.997]\n",
      ">229, d1[0.013] d2[0.059] g[30.386]\n",
      ">230, d1[0.105] d2[0.503] g[32.170]\n",
      ">231, d1[1.651] d2[0.011] g[30.974]\n",
      ">232, d1[0.935] d2[0.075] g[28.245]\n",
      ">233, d1[0.004] d2[0.328] g[29.044]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">234, d1[0.009] d2[0.055] g[29.585]\n",
      ">235, d1[0.039] d2[0.033] g[29.499]\n",
      ">236, d1[0.030] d2[0.038] g[29.361]\n",
      ">237, d1[0.013] d2[0.047] g[29.248]\n",
      ">238, d1[0.008] d2[0.046] g[29.345]\n",
      ">239, d1[0.011] d2[0.049] g[29.430]\n",
      ">240, d1[0.014] d2[0.063] g[29.502]\n",
      ">241, d1[0.024] d2[0.091] g[29.921]\n",
      ">242, d1[0.103] d2[0.262] g[31.211]\n",
      ">243, d1[0.565] d2[0.163] g[29.572]\n",
      ">244, d1[0.005] d2[0.082] g[30.416]\n",
      ">245, d1[0.015] d2[0.038] g[30.630]\n",
      ">246, d1[0.038] d2[0.069] g[30.428]\n",
      ">247, d1[0.026] d2[0.099] g[31.115]\n",
      ">248, d1[0.179] d2[0.980] g[32.935]\n",
      ">249, d1[2.243] d2[0.006] g[31.849]\n",
      ">250, d1[2.054] d2[0.023] g[29.938]\n",
      ">251, d1[1.380] d2[0.100] g[28.378]\n",
      ">252, d1[0.757] d2[0.267] g[27.464]\n",
      ">253, d1[0.434] d2[0.398] g[27.080]\n",
      ">254, d1[0.355] d2[0.391] g[26.964]\n",
      ">255, d1[0.362] d2[0.355] g[26.911]\n",
      ">256, d1[0.365] d2[0.333] g[26.810]\n",
      ">257, d1[0.360] d2[0.326] g[26.666]\n",
      ">258, d1[0.347] d2[0.325] g[26.605]\n",
      ">259, d1[0.324] d2[0.320] g[26.565]\n",
      ">260, d1[0.314] d2[0.309] g[26.546]\n",
      ">261, d1[0.304] d2[0.301] g[26.562]\n",
      ">262, d1[0.280] d2[0.292] g[26.559]\n",
      ">263, d1[0.266] d2[0.275] g[26.647]\n",
      ">264, d1[0.248] d2[0.267] g[26.549]\n",
      ">265, d1[0.220] d2[0.244] g[26.623]\n",
      ">266, d1[0.207] d2[0.225] g[26.727]\n",
      ">267, d1[0.166] d2[0.204] g[26.785]\n",
      ">268, d1[0.152] d2[0.185] g[26.830]\n",
      ">269, d1[0.128] d2[0.163] g[26.920]\n",
      ">270, d1[0.110] d2[0.143] g[26.979]\n",
      ">271, d1[0.085] d2[0.124] g[27.193]\n",
      ">272, d1[0.066] d2[0.107] g[27.235]\n",
      ">273, d1[0.055] d2[0.088] g[27.261]\n",
      ">274, d1[0.040] d2[0.077] g[27.518]\n",
      ">275, d1[0.040] d2[0.069] g[27.556]\n",
      ">276, d1[0.030] d2[0.063] g[27.641]\n",
      ">277, d1[0.026] d2[0.055] g[27.751]\n",
      ">278, d1[0.015] d2[0.051] g[27.815]\n",
      ">279, d1[0.017] d2[0.044] g[27.865]\n",
      ">280, d1[0.014] d2[0.040] g[28.045]\n",
      ">281, d1[0.011] d2[0.036] g[28.083]\n",
      ">282, d1[0.004] d2[0.033] g[28.095]\n",
      ">283, d1[0.013] d2[0.030] g[28.223]\n",
      ">284, d1[0.012] d2[0.029] g[28.304]\n",
      ">285, d1[0.009] d2[0.029] g[28.372]\n",
      ">286, d1[0.008] d2[0.027] g[28.348]\n",
      ">287, d1[0.006] d2[0.025] g[28.396]\n",
      ">288, d1[0.006] d2[0.024] g[28.451]\n",
      ">289, d1[0.004] d2[0.023] g[28.507]\n",
      ">290, d1[0.008] d2[0.023] g[28.605]\n",
      ">291, d1[0.005] d2[0.022] g[28.645]\n",
      ">292, d1[0.006] d2[0.021] g[28.604]\n",
      ">293, d1[0.006] d2[0.021] g[28.653]\n",
      ">294, d1[0.003] d2[0.022] g[28.685]\n",
      ">295, d1[0.006] d2[0.020] g[28.792]\n",
      ">296, d1[0.005] d2[0.021] g[28.759]\n",
      ">297, d1[0.007] d2[0.021] g[28.787]\n",
      ">298, d1[0.005] d2[0.022] g[28.753]\n",
      ">299, d1[0.006] d2[0.025] g[28.799]\n",
      ">300, d1[0.008] d2[0.028] g[28.814]\n",
      ">301, d1[0.008] d2[0.036] g[28.875]\n",
      ">302, d1[0.003] d2[0.044] g[28.934]\n",
      ">303, d1[0.019] d2[0.050] g[29.176]\n",
      ">304, d1[0.033] d2[0.078] g[29.572]\n",
      ">305, d1[0.021] d2[0.032] g[29.808]\n",
      ">306, d1[0.065] d2[0.086] g[29.931]\n",
      ">307, d1[0.024] d2[0.028] g[30.074]\n",
      ">308, d1[0.020] d2[0.027] g[29.991]\n",
      ">309, d1[0.010] d2[0.043] g[30.065]\n",
      ">310, d1[0.013] d2[0.044] g[30.249]\n",
      ">311, d1[0.018] d2[0.054] g[30.546]\n",
      ">312, d1[0.027] d2[0.040] g[30.601]\n",
      ">313, d1[0.023] d2[0.033] g[30.565]\n",
      ">314, d1[0.017] d2[0.054] g[30.776]\n",
      ">315, d1[0.016] d2[0.033] g[30.916]\n",
      ">316, d1[0.023] d2[0.068] g[30.926]\n",
      ">317, d1[0.028] d2[0.124] g[31.290]\n",
      ">318, d1[0.086] d2[0.153] g[31.054]\n",
      ">319, d1[0.024] d2[0.026] g[30.616]\n",
      ">320, d1[0.012] d2[0.047] g[30.472]\n",
      ">321, d1[0.014] d2[0.079] g[30.854]\n",
      ">322, d1[0.065] d2[0.071] g[30.811]\n",
      ">323, d1[0.026] d2[0.054] g[31.137]\n",
      ">324, d1[0.035] d2[0.053] g[31.282]\n",
      ">325, d1[0.021] d2[0.046] g[31.428]\n",
      ">326, d1[0.035] d2[0.069] g[31.903]\n",
      ">327, d1[0.034] d2[0.021] g[31.470]\n",
      ">328, d1[0.014] d2[0.099] g[32.416]\n",
      ">329, d1[0.201] d2[0.502] g[33.157]\n",
      ">330, d1[1.853] d2[0.008] g[31.473]\n",
      ">331, d1[0.502] d2[0.073] g[28.395]\n",
      ">332, d1[0.000] d2[0.645] g[29.958]\n",
      ">333, d1[0.004] d2[0.020] g[30.592]\n",
      ">334, d1[0.152] d2[0.023] g[29.617]\n",
      ">335, d1[0.003] d2[0.060] g[29.181]\n",
      ">336, d1[0.001] d2[0.122] g[29.800]\n",
      ">337, d1[0.013] d2[0.056] g[30.191]\n",
      ">338, d1[0.079] d2[0.345] g[31.619]\n",
      ">339, d1[0.751] d2[0.227] g[29.943]\n",
      ">340, d1[0.003] d2[0.054] g[30.523]\n",
      ">341, d1[0.010] d2[0.037] g[30.609]\n",
      ">342, d1[0.022] d2[0.057] g[30.601]\n",
      ">343, d1[0.026] d2[0.116] g[31.582]\n",
      ">344, d1[0.184] d2[0.525] g[33.023]\n",
      ">345, d1[1.863] d2[0.006] g[31.650]\n",
      ">346, d1[0.940] d2[0.058] g[28.433]\n",
      ">347, d1[0.002] d2[0.398] g[29.167]\n",
      ">348, d1[0.003] d2[0.059] g[29.856]\n",
      ">349, d1[0.016] d2[0.030] g[29.830]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-8970871e2ed7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgan_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-38-c7a4426054d6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(d_model, g_model, gan_model, dataset, n_epochs, n_batch, n_patch)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mX_realA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_realB\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_real_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_patch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# generate a batch of fake samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mX_fakeB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_fake_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_realA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_patch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;31m# update discriminator for real samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0md_loss1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_realA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_realB\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_real\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-c0378f2ee575>\u001b[0m in \u001b[0;36mgenerate_fake_samples\u001b[0;34m(g_model, samples, patch_shape)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_fake_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# generate fake instance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;31m# create 'fake' class labels (0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1167\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m                                             steps=steps)\n\u001b[0m\u001b[1;32m   1170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#dataset = (trainX,trainX)\n",
    "\n",
    "x = np.random.rand(1000, 256, 256, 3)\n",
    "y = np.random.rand(1000, 256, 256, 3)\n",
    "train(d_model, g_model, gan_model, (x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 256, 256, 3)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
